{
    "model_name": "model_v5",
    "vectorizer": "Word2Vec + TF-IDF (custom)",
    "accuracy": 0.9549,
    "date": "2025-05-24",
    "preprocessing": {
        "tokenization": "nltk word_tokenize",
        "stopwords": "NLTK english",
        "lemmatization": "WordNet POS-aware",
        "lowercase": true,
        "remove_punctuation": true
    },
    "vectorizer_params": "{'analyzer': <function identity at 0x36925c2c0>, 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 0.9, 'max_features': None, 'min_df': 0.01, 'ngram_range': (1, 3), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}",
    "model_params": "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}"
}